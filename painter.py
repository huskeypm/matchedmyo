from copy import copy
import numpy as np
import matplotlib.pyplot as plt
#import matplotlib.colors as colors
import matplotlib.mlab as mlab
import cv2
from scipy.misc import toimage
from scipy.ndimage.filters import *
from scipy import ndimage
import matchedFilter as mF
import imutils
#from matplotlib import cm
import detection_protocols as dps
from scipy import signal
import util 
#import util2


##
## Performs matched filtering over desired angles
##
def correlateThresher(
        inputs,
        params,
        iters = [0,30,60,90],  
        printer = True, 
        filterMode=None,
        label="undef",
        efficientRotationStorage = False
        ):
    '''This function iterates through the list of iters (rotation angles) and calls routines to 
    perform the convolution at each of these filter rotations.

    Inputs:
      inputs -> class. Generated by matchedmyo.giveMarkedMyocyte() or matchedmyo.give3DMarkedMyocyte()
      params -> dict. Parameter dictionary generated by optimizer.ParamDict() function
      iters -> list of ints. List of rotation angles with which we would like to perform convolution at
      printer -> Bool. If True, save the correlation plane for each rotation.
      filterMode -> str. Type of filtering being done. This is for display purposes.
      label -> str. String denoting the label we would like to give the plots
      efficientRotationStorage -> Bool. If true, we do not save the correlation plane for each rotation.
                                    This SIGNIFICANTLY reduces the RAM requirement for processing large
                                    images or large amounts of rotation at the cost of forgetting each
                                    rotation's correlation plane.
    
    Outputs:
      if efficientRotationStorage:
        correlated -> dict. Dictionary containing two entries:
                       'maxSNRArray' -> an array containing the maximum SNR calculated for that 
                          specific pixel/voxel.
                       'rotMaxSNRArray' -> an array containing the rotation (int or list) at which the 
                          certain pixel/voxel experienced the maximum SNR.
      else:
        correlated -> list. List of results class at each rotation that contains SNR and correlation plane
    '''
    ### NOTE: This is an artifact of old image classification code but still needs to be here for old code to work
    # TODO - this should be done in preprocessing, not here
    #print "PKH: turn into separate proproccessing routine"
    img = inputs.imgOrig
    
    if params['doCLAHE']:
      if img.dtype != 'uint8':
        myImg = np.array((img * 255),dtype='uint8')
      else:
        myImg = img
      clahe99 = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(16,16))
      img = clahe99.apply(myImg)

    ### NOTE: Begin code meant for this repository
    #filterRef = util.renorm(np.array(inputs.mfOrig,dtype=float),scale=1.)
    ### Save the unrotated filter as a reference
    filterRef = inputs.mfOrig.copy()
    
    ### Form storage arrays/lists needed for the analysis
    if efficientRotationStorage: 
      correlated = {}

      ## We need to create storage array for SNR at each pixel/voxel
      if params['inverseSNR']:
        ## If we use inverse SNR (meaning the SNR must be below a certain value to signify a hit), 
        ##   we need to create an array that has arbitrarily high starting numbers
        correlated['SNRArray'] = np.ones_like(img) * 5. * params['snrThresh']
      else:
        ## Otherwise, we can just instantiate the SNRArray with zeros
        correlated['SNRArray'] = np.zeros_like(img)

      ## We also need to create a storage array for the rotation which the maximum SNR occurred.
      if len(np.shape(img)) == 3:
        ## This means that the image is 3D and we must store the rotation arrays in 3 different arrays
        correlated['rotSNRArray'] = {}
        correlated['rotSNRArray']['x'] = np.zeros_like(img, dtype=np.int8) - 1
        correlated['rotSNRArray']['y'] = np.zeros_like(img, dtype=np.int8) - 1
        correlated['rotSNRArray']['z'] = np.zeros_like(img, dtype=np.int8) - 1
      else:
        ## Otherwise we only need one array to store the single rotation
        correlated['rotSNRArray'] = np.zeros_like(img,dtype=np.int8) - 1
    else:
      ## Store all 'hits' at each angle 
      correlated = []

    ### Iterate over all filter rotations desired
    for i in iters:
      ## Check dimensionality of iteration and rotate filters accordingly
      if type(i) == list:
        ## This is 3D
        ## pad/rotate filter
        rFN = util.rotate3DArray_Nonhomogeneous(filterRef,i,inputs.scopeResolutions)
        ## Depad the array to reduce computational expense
        rFN = util.autoDepadArray(rFN)
        inputs.mf = rFN

        ## check to see if we need to rotate other matched filters for the detection
        if params['filterMode'] == 'punishmentFilter':
          params['mfPunishmentRot'] = util.rotate3DArray_Nonhomogeneous(params['mfPunishment'].copy(),i,inputs.scopeResolutions)
          params['mfPunishmentRot'] = util.autoDepadArray(params['mfPunishmentRot'])
      else:
        ## This is 2D
        ## pad/rotate 
        params['angle'] = i
        rFN = util.PadRotate(filterRef,i)  
        ## Depad the array to reduce computational expense
        rFN = util.autoDepadArray(rFN)
        inputs.mf = rFN  

        ## check for other matched filters
        if params['filterMode'] == 'punishmentFilter':
          params['mfPunishmentRot'] = util.PadRotate(params['mfPunishment'].copy(),i)
      
      ## Perform matched filtering 
      result = dps.FilterSingle(inputs,params)      

      ## Check to see what our storage scheme is and store accordingly
      if efficientRotationStorage:
        ## Get element-wise comparison of this rotation's SNR to all previous SNRs
        if params['inverseSNR']:
          ## If we're using the inverseSNR scheme of hit detection, we need which SNRs are less
          ##   at this rotation than previous SNRs at previous rotations 
          SNRcomparison = np.less(result.snr, correlated['SNRArray'])
        else:
          ## Otherwise, we just pick out the SNRs which are greater at this rotation compared to
          ##   previous rotations
          SNRcomparison = np.greater(result.snr, correlated['SNRArray'])

        ## Pick out the greater SNRs and store in maxSNRArray
        correlated['SNRArray'][SNRcomparison] = result.snr[SNRcomparison]

        ## Pick out the rotations at which the maximum SNR is located at the current location and 
        ##   store in the array
        if len(np.shape(img)) == 3:
          correlated['rotSNRArray']['x'][SNRcomparison] = i[0]
          correlated['rotSNRArray']['y'][SNRcomparison] = i[1]
          correlated['rotSNRArray']['z'][SNRcomparison] = i[2]
        else:  
          correlated['rotSNRArray'][SNRcomparison] = i

      else:
        ## Store results contain both correlation plane and snr
        result.rFN = np.copy(rFN)
        correlated.append(result) 

    ## Write the correlation planes if this is desired
    if printer and not efficientRotationStorage: 
       if label==None:
         label="undef"
       if filterMode==None:
         filterMode="undef"

       for i, angle in enumerate(iters):
        tag = filterMode 
        daTitle = "rot %4.1f "%angle # + "hit %4.1f "%hit 

        result = correlated[i]   
        plt.figure()
        plt.subplot(1,2,1)
        plt.title("Rotated filter") 
        plt.imshow(result.rFN,cmap='gray')
        plt.subplot(1,2,2)
        plt.title("Correlation plane") 
        plt.imshow(result.corr)                
        plt.colorbar()
        plt.tight_layout()
        fileName = label+"_"+tag+'_{}.png'.format(angle)
        plt.gcf().savefig(fileName,dpi=300)
        plt.close()

    return correlated  # a list of objects that contain SNR, etc 

##
## Collects all hits above some criterion for a given angle and 'stacks' them
## into a single image
##
def StackHits(correlated,  # an array of 'correlation planes'
              paramDict, # threshold,
              iters,
              display=False,
              rescaleCorr=False,
              doKMeans=False, #True,
              returnAngles=False,
              efficientRotationStorage=False):
    '''This function goes through and 'stacks' the hits across all rotations if this hasn't been 
    done previously. This is necessary when efficientRotationStorage is False.

    Inputs:
      correlated -> list or dict. If efficientRotationStorage is False. Correlated is a list of
                      results classes (see correlateThresher function for objects in class).
                      If efficientRotationStorage is True, this is a dict. The keys of which
                      can also be seen in correlateThresher.
      paramDict -> dict. Dictionary containing parameters for the characterization routines. 
                     Generated via optimizer.ParamDict() function.
      iters -> list of ints (2D classification) or list of list of int (3D classification).
                List of rotations to consider for the classification.
      display -> Bool. If True, saves plots for debugging.
      rescaleCorr -> Deprecated.
      doKMeans -> Deprecated.
      returnAngles -> Boolean. If True, return the angles with which the greatest SNR appears.
      efficientRotationStorage -> Bool. If True, correlated already contains 'stacked' hits
                                    and that simplifies this routine immensely.
    
    Outputs:
      stacked -> array. Array with same dimensions as image where hits are marked with their 
                   maximum SNR across all rotations and non-hits are marked with NaNs
      if returnAngles:
        if image is 2D:
          stackedAngles -> array. Array with same shape as image where hits are marked as their
                             rotation of maximum SNR and non-hits are marked as -1.
        elif image is 3D:
          stackedAngles -> dict. Dictionary containing arrays containing rotation info for 
                            x, y, and z where keys are 'x', 'y', and 'z', respectively.
    '''
     # TODO
    if rescaleCorr:
      raise RuntimeError("Why is this needed? IGNORING")
    if display:
      print "Call me debug" 

    ### Check to see if we previously used the new storage technique
    ###   if we did, then we can use a shortcut with this routine since we've done a lot of the leg
    ###   work already. Else, we'll have to do some more work to stack the detection or hits.
    if efficientRotationStorage:
      ## We've already wrote the previous routines in a way that we have the maximum SNR and stackedAngles 
      ##   in a format close to compatible with the other routines. We just need to mask out non-hits
      stackedHits = util.makeMask(paramDict['snrThresh'],
                                  img = correlated['SNRArray'],
                                  inverseThresh = paramDict['inverseSNR'])
      if returnAngles:
        ## Now we fix the stackedAngles format
        stackedAngles = correlated['rotSNRArray']
        return stackedHits, stackedAngles
      else:
        return stackedHits

    ### Otherwise, we have to do some work to pick out the SNRs of our hits across all rotations
    ###   First, we select hits based on those entries about the snrThresh 
    maskList = []
    simpleCorrMaskList = []
    for i, iteration in enumerate(iters):
        ## routine for identifying 'unique' hits
        try:
          daMask = util.makeMask(paramDict['snrThresh'],img = correlated[i].snr,
                                  inverseThresh=paramDict['inverseSNR'])
        except:
          print "DC: Using workaround for tissue param dictionary. Fix me."
          daMask = util.makeMask(paramDict['snrThresh'], img=correlated[i].snr)
        ## pull out where there is a hit on the simple correlation for use in rotation angle
        hitMask = daMask > 0.
        simpleCorrMask = correlated[i].corr
        simpleCorrMask[np.logical_not(hitMask)] = 0
                                  
        ##  print debugging info                                    
        if display:
            plt.figure()
            plt.subplot(2,1,1)
            plt.imshow(correlated[i].snr)
            plt.colorbar()
            plt.subplot(2,1,2)
            plt.imshow(daMask,cmap="gray")
            #plt.axis("off")
            plt.gcf().savefig("stack_%d.png"%iteration)    

        maskList.append(daMask)
        simpleCorrMaskList.append(simpleCorrMask)

    # take maximum hit
    stacked = np.max(maskList,axis=0)
    
    # default behavior (just returned stacked images) 
    if not returnAngles:
      return stacked 
    
    # function that returns angle associated with optimal response
    if returnAngles:
      # have to subtract one from array so that we can use this to index rotations later on in alg
      doSimple = False
      if doSimple:
        stackedAngles = np.argmax(simpleCorrMaskList,axis=0)
        # mask out non hits
        stackedAngles[stacked == 0] = -1
      else:
        stackedAngles = np.argmax(maskList,axis=0)
        stackedAngles[stacked == 0] = -1
      return stacked, stackedAngles
  
###
### Function to color the angles previously returned in StackHits
###   
def colorAngles(rawOrig, stackedAngles,iters,leftChannel='red',rightChannel='blue'):
  channelDict = {'blue':0, 'green':1, 'red':2}

  dims = np.shape(stackedAngles)

  if len(np.shape(rawOrig)) > 2:
    coloredImg = rawOrig.copy()
    #plt.figure()
    #plt.imshow(coloredImg)
    #plt.show()
    #quit()
  else:
    # we need to make an RGB version of the image
    coloredImg = np.zeros((dims[0],dims[1],3),dtype='uint8')
    scale = 0.75
    coloredImg[:,:,0] = scale * rawOrig
    coloredImg[:,:,1] = scale * rawOrig
    coloredImg[:,:,2] = scale * rawOrig

  leftmostIdx = 0 # mark as left channel
  rightmostIdx = len(iters) # mark as right channel
  # any idx between these two will be colored a blend of the two channels

  spacing = 255 / rightmostIdx

  for i in range(dims[0]):
    for j in range(dims[1]):
      rotArg = stackedAngles[i,j]
      if rotArg != -1:
        coloredImg[i,j,channelDict[leftChannel]] = int(255 - rotArg*spacing)
        coloredImg[i,j,channelDict[rightChannel]] = int(rotArg*spacing)
  return coloredImg

# Basically just finds a 'unit cell' sized area around each detection 
# for the purpose of interpolating the data 
def doLabel(result,cellDimensions = [10, None, None],thresh=0):
  '''
  Finds a unit cell sized area around each detection. This serves to display more intuitive representations 
    of detections. This is for 2 and 3 dimensional data.
  
  Inputs:
    result -> class. Result class from bankDetect.DetectFilter(). result.stackedHits is where the detetions are stored.
    cellDimensions -> list of ints. Measurement of the unit cell dimensions in the x, y, and z directions.
                   Specification of y and z is optional but should be specified for accurate results.
                   Specification of z only needed if image is 3D.
    thresh -> int or float. Threshold applied to result.stackedHits to determine where the hits are.

  Outputs:
    labeled -> boolean array. The image with detections dilated according to unit cell size.
  '''
  if len(result.stackedHits.shape) == 3:
    dx, dy, dz = cellDimensions
  else:
    dx, dy = cellDimensions

  ### Determine dimensions of unit cell if none are specified. If dy and dz are not specified, set equal to dx
  if dy == None:
    dy = dx
  if len(result.stackedHits.shape) == 3:
    if dz == None:
      dz = dx
  
  ### Determine where hits are present in stackedHits based on threshold
  img =result.stackedHits > thresh

  ### Construct kernel the size of the unit cell
  if len(result.stackedHits.shape) == 3:
    kernel = np.ones((dx,dy,dz),np.float32)/(float(dy*dx*dz))
  else:
    kernel = np.ones((dx,dy),np.float32)/(float(dy*dx))
  
  ### Perform convolution to determine where kernel overlaps with detection
  if len(result.stackedHits.shape) == 3:
    filtered = ndimage.convolve(img.astype(float), kernel) / np.sum(kernel)
  else:
    filtered = signal.convolve2d(img, kernel, mode='same') / np.sum(kernel)

  ### Perform boolean operation to pull out all dilated hits
  labeled = filtered > 0
  
  return labeled

def WT_SNR(Img, WTfilter, WTPunishmentFilter,C,gamma):
  # calculates SNR of WT filter
  
  # get two responses
  h = mF.matchedFilter(Img, WTfilter, demean=False)
  h_star = mF.matchedFilter(Img,WTPunishmentFilter,demean=False)
  
  # calculate SNR
  SNR = h / (C + gamma * h_star)

  return SNR
